{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f92549e-83bc-4269-a79c-a2e3ed9684fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lussi.stackoverflow import *\n",
    "from lussi.ziprecruiter import *\n",
    "\n",
    "\"\"\"\n",
    "Run like this: \n",
    "(.venv) hurricane:krijudato afraser$ python ./src/lussi/run.py\n",
    "\"\"\"\n",
    "\n",
    "# run this to build out your caches.\n",
    "nogit_data_dir = \"622data_nogit\"\n",
    "#build_stack(data_dir=nogit_data_dir)\n",
    "#build_zip(data_dir=nogit_data_dir)\n",
    "\n",
    "# this is how you load.\n",
    "raw_stack  = load_stack(data_dir = nogit_data_dir, stack_type=StackType.RAW)\n",
    "wide_stack = load_stack(data_dir = nogit_data_dir, stack_type=StackType.WIDE)\n",
    "ziprecruiter = load_zip(data_dir = nogit_data_dir)\n",
    "\n",
    "#print(raw_stack.head())\n",
    "#print(wide_stack.head())\n",
    "#print(ziprecruiter.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856db053-000b-479a-929a-6a9daea86879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# encoding / preprocessing\n",
    "# filter for US only\n",
    "us_data = wide_stack[wide_stack['Country'] == 'United States']\n",
    "\n",
    "# filter for only 2022\n",
    "us_data = us_data[us_data['Year'] == 2022]\n",
    "\n",
    "# Function to categorize gender based on the provided rules\n",
    "def group_gender(gender):\n",
    "    gender = str(gender).lower()  # Convert to lowercase \n",
    "    if 'female' in gender or 'woman' in gender:\n",
    "        return 'Female'\n",
    "    elif 'male' in gender or 'man' in gender:\n",
    "        return 'Male'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the function to the 'Gender' column to create 'gender_grouped'\n",
    "us_data.loc[:, 'gender_grouped'] = us_data['Gender'].apply(group_gender)\n",
    "\n",
    "# columns to drop \n",
    "cols_to_drop = ['Year', 'OrgSize', 'Country', 'Employment', 'Gender', 'EdLevel',\n",
    "       'US_State', 'Age', 'DevType', 'Sexuality', 'Ethnicity',\n",
    "       'DatabaseWorkedWith', 'LanguageWorkedWith', 'PlatformWorkedWith',\n",
    "       'YearsCodePro','python', 'sql', 'java', 'javascript', 'ruby', 'php', 'c',\n",
    "       'swift', 'scala', 'r', 'rust', 'julia',  'microsoftsqlserver',\n",
    "       'mongodb', 'postgresql', 'oracle', 'ibmdb2', 'redis', 'sqlite',\n",
    "       'mariadb', 'microsoftazure', 'googlecloud', 'ibmcloudorwatson',\n",
    "       'kubernetes', 'linux', 'windows']\n",
    "\n",
    "# new dataframe with columns dropped\n",
    "df = us_data.drop(columns=cols_to_drop)\n",
    "\n",
    "df_new=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d834fb77-b1ef-4c5d-a7a9-73dbc63d19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost\n",
    "\n",
    "# Convert categorical columns to 'category' dtype\n",
    "#categorical_cols = ['mysql', 'aws', 'sexuality_grouped', 'ethnicity_grouped', 'gender_grouped']  # Add any other categorical columns you have\n",
    "#for col in categorical_cols:\n",
    "#    df_new[col] = df_new[col].astype('category')\n",
    "\n",
    "# define variables - select all variables except the target variable\n",
    "X = df_new.drop(columns=['AnnualSalary'])\n",
    "\n",
    "# define target variable\n",
    "Y = df_new['AnnualSalary']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Identify all boolean columns\n",
    "bool_cols = X_encoded.select_dtypes(include=['bool']).columns\n",
    "\n",
    "# Convert boolean columns to integers (True -> 1, False -> 0)\n",
    "X_encoded[bool_cols] = X_encoded[bool_cols].astype(int)\n",
    "\n",
    "# Split the dataset into 80% training and 20% testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with the mean \n",
    "Y_train_imputed = Y_train.fillna(Y_train.mean()) \n",
    "\n",
    "# Impute numeric columns using 'mean' strategy\n",
    "numeric_cols = ['YearsCodeProAvg', 'OrgSizeAvg', 'AgeAvg']\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Applied StandardScalar to numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select the columns to scale\n",
    "columns_to_scale = ['YearsCodeProAvg', 'OrgSizeAvg', 'AgeAvg']\n",
    "\n",
    "# Fit and transform the scaler\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d334830-db31-4b2d-84b6-6a7f033acb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  938992.816527\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "# Instantiation \n",
    "xgb_r = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                         n_estimators=100, \n",
    "                         learning_rate=0.1, \n",
    "                         max_depth=6, \n",
    "                         enable_categorical=True,  # Enable categorical feature handling\n",
    "                         seed=123) \n",
    "  \n",
    "# Fitting the model \n",
    "xgb_r.fit(X_train, Y_train_imputed) \n",
    "  \n",
    "# Predict the model \n",
    "pred = xgb_r.predict(X_test) \n",
    "\n",
    "# Assuming Y_test is a pandas Series\n",
    "Y_test_imputed = Y_test.copy()  # Create a copy to avoid modifying the original\n",
    "Y_test_imputed.fillna(Y_test.mean(), inplace=True)  # Mean imputation\n",
    "\n",
    "# compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_imputed, pred)) \n",
    "print(\"RMSE : % f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57b3bbc5-64d0-4648-9da2-cc64174c6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 10, 'n_estimators': 238, 'subsample': 1.0}\n",
      "Optimized RMSE:  900341.084831\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Instantiate the model and RandomizedSearchCV\n",
    "xgb_r = xgb.XGBRegressor(objective='reg:squarederror', seed=123)\n",
    "random_search = RandomizedSearchCV(estimator=xgb_r, param_distributions=param_grid, n_iter=50, scoring='neg_mean_squared_error', cv=5, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, Y_train_imputed)\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "\n",
    "# Predict using the best model\n",
    "best_model = random_search.best_estimator_\n",
    "pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_imputed, pred))\n",
    "print(\"Optimized RMSE: % f\" % (rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7c692f0-bfeb-4f5e-8af5-59582d23559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: -0.001739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predict the model on the test data\n",
    "pred = random_search.predict(X_test)\n",
    "\n",
    "# Compute the R² score\n",
    "r2 = r2_score(Y_test_imputed, pred)\n",
    "print(\"R²: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb2c2a-45f5-48f7-87cb-ade7d9e70649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

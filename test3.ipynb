{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18de41b3-385e-4d99-9672-fc2b34370f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f92549e-83bc-4269-a79c-a2e3ed9684fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lussi.stackoverflow import *\n",
    "from lussi.ziprecruiter import *\n",
    "\n",
    "\"\"\"\n",
    "Run like this: \n",
    "(.venv) hurricane:krijudato afraser$ python ./src/lussi/run.py\n",
    "\"\"\"\n",
    "\n",
    "# run this to build out your caches.\n",
    "nogit_data_dir = \"622data_nogit\"\n",
    "#build_stack(data_dir=nogit_data_dir)\n",
    "#build_zip(data_dir=nogit_data_dir)\n",
    "\n",
    "# this is how you load.\n",
    "raw_stack  = load_stack(data_dir = nogit_data_dir, stack_type=StackType.RAW)\n",
    "wide_stack = load_stack(data_dir = nogit_data_dir, stack_type=StackType.WIDE)\n",
    "ziprecruiter = load_zip(data_dir = nogit_data_dir)\n",
    "\n",
    "#print(raw_stack.head())\n",
    "#print(wide_stack.head())\n",
    "#print(ziprecruiter.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a21c30-0061-4809-b2d4-48f98c9f1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_gender(gender):\n",
    "    gender = str(gender).lower()  # converts to lowercase \n",
    "    if 'female' in gender or 'woman' in gender:\n",
    "        return 'Female'\n",
    "    elif 'male' in gender or 'man' in gender:\n",
    "        return 'Male'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "filtered_stack = (\n",
    "    wide_stack\n",
    "    .query(\"Year != 2019 and Year != 2020\")  # No salary\n",
    "    .query(\"Year != 2017\")  # No age\n",
    "    .query(\"Country == 'United States'\")  # Forget that!\n",
    "    .assign(gender_grouped=wide_stack['Gender'].apply(group_gender))  # Add gender_grouped, simplify to m/f/o\n",
    "    .drop('Gender', axis=1) \n",
    "    .drop('Sexuality', axis=1)  # DE: sexuality_grouped as either straight or lgbtq+\n",
    "    .drop('Ethnicity', axis=1)  # DE: ethnicity_grouped, either minority or non-minority\n",
    "    .drop('PlatformWorkedWith', axis=1)  #DE: expanded in calculated columns\n",
    "    .drop('LanguageWorkedWith', axis=1)  #DE: expanded in calculated columns\n",
    "    .drop('DatabaseWorkedWith', axis=1)  #DE: expanded in calculated columns\n",
    "    .drop('US_State', axis=1) # too few \n",
    "    .drop('Country', axis=1) \n",
    "    .drop('YearsCodePro', axis=1) # DE: We built YearsCodeProAvg integer column to replace this.\n",
    "    .drop('OrgSize', axis=1) # DE: We built YearsCodeProAvg in DE\n",
    "    .drop('Age', axis=1) # DE: we built average age for this.\n",
    "   # .drop('DevType', axis=1) # too self reported to be much use.\n",
    "    .query('AnnualSalary > 1')   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856db053-000b-479a-929a-6a9daea86879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Employment', 'EdLevel', 'DevType', 'AnnualSalary',\n",
      "       'YearsCodeProAvg', 'OrgSizeAvg', 'AgeAvg', 'python', 'sql', 'java',\n",
      "       'javascript', 'ruby', 'php', 'c', 'swift', 'scala', 'r', 'rust',\n",
      "       'julia', 'mysql', 'microsoftsqlserver', 'mongodb', 'postgresql',\n",
      "       'oracle', 'ibmdb2', 'redis', 'sqlite', 'mariadb', 'microsoftazure',\n",
      "       'googlecloud', 'ibmcloudorwatson', 'kubernetes', 'linux', 'windows',\n",
      "       'sexuality_grouped', 'ethnicity_grouped', 'aws', 'gender_grouped'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# encoding / preprocessing\n",
    "us_data = filtered_stack\n",
    "\n",
    "# columns to keep (all features but DevType as there was too self reported to be much use)\n",
    "#cols_to_keep = ['AnnualSalary','YearsCodeProAvg', 'OrgSizeAvg', \n",
    "#                'scala', 'python', 'javascript', 'EdLevel',\n",
    "#                'postgresql', 'ethnicity_grouped', 'AgeAvg', \n",
    "#               'gender_grouped','aws','mysql','redis','sql',\n",
    "#               'java','ruby','php','c','mongodb',\n",
    "#               'oracle','ibmdb2','sqlite','kubernetes',\n",
    "#               'linux','windows', 'sexuality_grouped']\n",
    "\n",
    "cols_to_keep =['Year', 'Employment', 'EdLevel', 'AnnualSalary',\n",
    "       'YearsCodeProAvg', 'OrgSizeAvg', 'AgeAvg', 'python', 'sql', 'java',\n",
    "       'javascript', 'ruby', 'php', 'c', 'swift', 'scala', 'r', 'rust',\n",
    "       'julia', 'mysql', 'microsoftsqlserver', 'mongodb', 'postgresql',\n",
    "       'oracle', 'ibmdb2', 'redis', 'sqlite', 'mariadb', 'microsoftazure',\n",
    "       'googlecloud', 'ibmcloudorwatson', 'kubernetes', 'linux', 'windows',\n",
    "       'sexuality_grouped', 'ethnicity_grouped', 'aws', 'gender_grouped']\n",
    "\n",
    "# new dataframe with specific columns\n",
    "df_new = us_data[cols_to_keep].copy()\n",
    "\n",
    "print(us_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c44157a-3e60-4166-ae25-b0c276aabb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df_new['AnnualSalary'].quantile(0.25)\n",
    "Q3 = df_new['AnnualSalary'].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers from the dataframe\n",
    "df_filtered = df_new[(df_new['AnnualSalary'] >= lower_bound) & (df_new['AnnualSalary'] <= upper_bound)]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df_filtered, drop_first=True)\n",
    "\n",
    "# Identify all boolean columns\n",
    "bool_cols = df_encoded.select_dtypes(include=['bool']).columns\n",
    "\n",
    "# Convert boolean columns to integers (True -> 1, False -> 0)\n",
    "df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)\n",
    "\n",
    "# Update X and Y with the filtered data\n",
    "X = df_encoded.drop(columns=['AnnualSalary'])\n",
    "Y = df_encoded['AnnualSalary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834fb77-b1ef-4c5d-a7a9-73dbc63d19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% training and 20% testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# impute target variable train set\n",
    "#Y_train_imputed = Y_train.copy().values.reshape(-1, 1)  \n",
    "#Y_train_imputed = knn_imputer.fit_transform(Y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee593ca-08a2-4536-add8-84e88b27ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import RFE\n",
    "\n",
    "#model = xgb.XGBRegressor()\n",
    "#rfe = RFE(model, n_features_to_select=10)  # Select top 10 features\n",
    "#fit = rfe.fit(X_train, Y_train_imputed)\n",
    "#print(fit.support_)  # Boolean mask of selected features\n",
    "\n",
    "# Get the names of the features\n",
    "#feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to show selected features\n",
    "#selected_features = feature_names[selected_features_mask]\n",
    "#print(selected_features)\n",
    "\n",
    "# selects which features to keep in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1112f-9d6e-4065-b512-168312bdc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(Y_train)\n",
    "plt.title('Boxplot of Target Variable (Y_train)')\n",
    "plt.ylabel('Target Variable Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792bd1b-30db-41fd-9678-0b1766ec16f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_matrix = df_encoded.drop(columns=['AnnualSalary']).corr()\n",
    "sns.heatmap(corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3bbc5-64d0-4648-9da2-cc64174c6465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': randint(200, 1000), # initial was randint(100, 500) ; updated was randint(200, 1000)\n",
    "     'max_depth': randint(2,6), # initial was (3,10); updated to  (2,6)\n",
    "     'learning_rate': [0.01, 0.05, 0.1], # initial was [0.001, 0.01, 0.1, 0.3]; updated to [0.01, 0.05, 0.1]\n",
    "     'subsample': [0.6, 0.8, 1.0],\n",
    "     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "     'gamma': [0, 0.1, 0.3, 0.5],\n",
    "     'min_child_weight': [10, 15, 20] # inital was [1,5,10]; updated to [10, 15, 20]\n",
    "}\n",
    "\n",
    "# Instantiate the model and RandomizedSearchCV\n",
    "xgb_r = xgb.XGBRegressor(objective='reg:squarederror', seed=123)\n",
    "random_search = RandomizedSearchCV(estimator=xgb_r, \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_iter=50, \n",
    "                                   scoring='neg_mean_squared_error', \n",
    "                                   cv=5, \n",
    "                                   verbose=1, \n",
    "                                   random_state=42)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, Y_train)\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "\n",
    "# Predict using the best model\n",
    "best_model = random_search.best_estimator_\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b0171-f548-4b00-8f74-a0fe56a8a66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f101f1-757f-4ddf-9a74-255b57ce1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "xgb.plot_importance(best_model, importance_type='weight', max_num_features=20)\n",
    "plt.title('Top Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c692f0-bfeb-4f5e-8af5-59582d23559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the R² score\n",
    "r2 = r2_score(Y_test, pred)\n",
    "print(\"R²: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb2c2a-45f5-48f7-87cb-ade7d9e70649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "residuals = Y_test - pred  # Calculate residuals\n",
    "\n",
    "# create data frame for plotting\n",
    "residuals_df = pd.DataFrame({\n",
    "    'Actual': Y_test,\n",
    "    'Predicted': pred,\n",
    "    'Residuals': residuals\n",
    "})\n",
    "\n",
    "# Plot Residuals vs Predicted Values\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Predicted', y='Residuals', data=residuals_df)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Predicted Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of Residuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q Plot\n",
    "sm.qqplot(residuals, line='s')\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaace3c6-2402-44e2-a7c4-0c0e362951df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the training set\n",
    "train_pred = best_model.predict(X_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "test_pred = best_model.predict(X_test)\n",
    "\n",
    "# RMSE on the training set\n",
    "train_rmse = np.sqrt(mean_squared_error(Y_train, train_pred))\n",
    "print(f\"Training RMSE: {train_rmse}\")\n",
    "\n",
    "# RMSE on the testing set\n",
    "test_rmse = np.sqrt(mean_squared_error(Y_test, test_pred))\n",
    "print(f\"Testing RMSE: {test_rmse}\")\n",
    "\n",
    "# R² on the training set\n",
    "train_r2 = r2_score(Y_train, train_pred)\n",
    "print(f\"Training R²: {train_r2}\")\n",
    "\n",
    "# R² on the testing set\n",
    "test_r2 = r2_score(Y_test, test_pred)\n",
    "print(f\"Testing R²: {test_r2}\")\n",
    "\n",
    "# this suggests that the model is not overfitting and it's performing similarly on the test & train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922db1b-3a83-442b-980d-62ed9ec595e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "#df_encoded_outlier = pd.get_dummies(df_new, drop_first=True)\n",
    "\n",
    "# Identify all boolean columns\n",
    "#bool_cols_outlier = df_encoded.select_dtypes(include=['bool']).columns\n",
    "\n",
    "# Convert boolean columns to integers (True -> 1, False -> 0)\n",
    "#df_encoded_outlier[bool_cols] = df_encoded_outlier[bool_cols].astype(int)\n",
    "\n",
    "# Update X and Y with the filtered data\n",
    "#X_out = df_encoded_outlier.drop(columns=['AnnualSalary'])\n",
    "#Y_out = df_encoded_outlier['AnnualSalary']\n",
    "\n",
    "# Split the dataset into 80% training and 20% testing data\n",
    "#X_train_out, X_test_out, Y_train_out, Y_test_out = train_test_split(X_out, Y_out, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "#param_grid = {\n",
    "#    'n_estimators': randint(200, 1000), # initial was randint(100, 500) ; updated was randint(200, 1000)\n",
    "#     'max_depth': randint(2,6), # initial was (3,10); updated to  (2,6)\n",
    "#     'learning_rate': [0.01, 0.05, 0.1], # initial was [0.001, 0.01, 0.1, 0.3]; updated to [0.01, 0.05, 0.1]\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#     'gamma': [0, 0.1, 0.3, 0.5],\n",
    "#     'min_child_weight': [10, 15, 20] # inital was [1,5,10]; updated to [10, 15, 20]\n",
    "#}\n",
    "\n",
    "# Instantiate the model and RandomizedSearchCV\n",
    "#xgb_r_out = xgb.XGBRegressor(objective='reg:squarederror', seed=123)\n",
    "#random_search_out = RandomizedSearchCV(estimator=xgb_r_out, \n",
    "#                                   param_distributions=param_grid, \n",
    "#                                   n_iter=50, \n",
    "#                                   scoring='neg_mean_squared_error', \n",
    "#                                   cv=5, \n",
    "#                                   verbose=1, \n",
    "#                                   random_state=42)\n",
    "\n",
    "# Fit the random search model\n",
    "#random_search_out.fit(X_train_out, Y_train_out)\n",
    "#print(f\"Best parameters: {random_search_out.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05e26d-25ba-4c2f-8210-53f61c9c26fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc60a2-d5e6-4e5d-99a4-a6c70736e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the best model\n",
    "best_model_out = random_search_out.best_estimator_\n",
    "pred_out = best_model_out.predict(X_test_out)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse_out = np.sqrt(mean_squared_error(Y_test_out, pred_out))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Compute the R² score\n",
    "r2_out = r2_score(Y_test_out, pred_out)\n",
    "print(\"R²: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a5d08-3974-4740-811b-b3f0b08c0025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

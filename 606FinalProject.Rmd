---
title: A Comprehensive Analysis of Gender Pay Gap in the Tech Industry Using Stack
  Overflow Survey Data
author: "Kristin Lussi and Tony Fraser"
date: "December 7th, 2023"
output:
  slidy_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract
<!-- Summarize analysis -->
<!-- Research methods -->
<!-- Findings/conclusion -->
<!-- Significance of our findings -->

* Summary

This research paper uses six years' worth of the annual Stack Overflow survey data to examine the gender pay gap within the technology sector. Given the source, this self-reported response data isn't necessarily specific to any industry but more about what people do as a job function. This data spans a variety of tech positions such as R programmer, cloud engineer, technical project manager, blockchain developer, etc.

* Research Methods

In this research paper, you will find an overview of descriptive statistics describing the data and specific examples of the gender pay gap. Additionally, we conduct a deep dive using multiple linear regression for some of our more advanced analyses.

* Findings and Conclusion

It is clear from this data that there is a significant pay gap. However, even using this massive dataset, there is at least one more critical and yet undefined variable that must be added to model the pay gap. Without the column named "CompanyPercentSexist" in this dataset, we hypothesize that modeling this gap may never be possible.

* Significance of Findings

If nothing else, we need to delve further into this issue. We would like to attempt to collect some funding and perform additional modeling. Our initial ideas involve presenting some additional questions to Stack Overflow, particularly related to geography and industry. While we might not be able to find "CompanyPercentSexist," at least if we can narrow down industry and region, we can report key information to local politicians and the media.

<!-- 
By using a data set that includes responses from a range of tech professionals, our goal is to offer a detailed insight into the factors that contribute to the identified trends in the gender pay gap. 
The results of this study could guide evidence-based efforts to promote inclusivity and equality, ultimately benefiting both the technology sector and society as a whole. -->

## Introduction

The gender pay gap within the US tech sector has long been a subject of concern, reflecting broader societal issues and potential barriers to gender equity. 
This research paper leverages a data set built From six years / 1.55GB of Stack Overflow [survey data](https://survey.stackoverflow.co) to examine the pay 
gap across many variables. 

Our aim is to answer the question, **Is there a significant difference in salary between males and females within the tech industry?**

The dependent variable is *Annual Salary*. We will utilize multiple linear regression to first determine if we can reject the null hypothesis. The null hypothesis ($H_0$) is: **There is no significant difference in the mean annual salaries between male and females.** The alternative hypothesis ($H_1$) is: **There is a significant difference in the mean annual salaries between males and females.** Once we determine if we can reject the null hypothesis, we will determine which variables are statistically significant in predicting the response variable (Annual Salary).

## Data Overview

```{r, warning = FALSE, message = FALSE, echo = FALSE, show = FALSE, output = FALSE}
source("functions.r")
library(dplyr)
library(psych)
library(gt)
library(stringr)
library(gridExtra)

set.seed(4299)

options(scipen=999)
wide_stack <- get_stack_df(persist = TRUE, load_from_cache = TRUE)

wide_stack <- wide_stack %>%
  mutate(
    python_num = ifelse(python == "yes", 1, 0),
    sql_num = ifelse(sql == "yes",1, 0),
    java_num = ifelse(java == "yes", 1, 0),
    javascript_num = ifelse(javascript == 'yes', 1, 0),
    ruby_num = ifelse(ruby == 'yes',1,0),
    php_num = ifelse(php == 'yes',1,0),
    c_num = ifelse(c == 'yes',1,0),
    swift_num = ifelse(swift == 'yes',1,0),
    scala_num = ifelse(scala == 'yes',1,0),
    r_num = ifelse(r == 'yes',1,0),
    rust_num=ifelse(rust == 'yes',1,0),
    julia_num = ifelse(julia == 'yes',1,0),
    mysql_num = ifelse(mysql == 'yes',1,0),
    microsoftsqlserver_num = ifelse(microsoftsqlserver=='yes',1,0),
    mongodb_num = ifelse(mongodb=='yes',1,0),
    postgresql_num=ifelse(postgresql=='yes',1,0),
    oracle_num = ifelse(oracle=='yes',1,0),
    ibmdb2_num = ifelse(ibmdb2 == 'yes', 1,0),
    redis_num = ifelse(redis=='yes',1,0),
    sqlite_num = ifelse(sqlite=='yes',1,0),
    mariadb_num = ifelse(mariadb=='yes',1,0),
    microsoftazure_num = ifelse(microsoftazure == 'yes',1,0),
    googlecloud_num = ifelse(googlecloud=='yes',1,0),
    ibmcloudorwatson_num = ifelse(ibmcloudorwatson=='yes', 1,0),
    kubernetes_num = ifelse(kubernetes=='yes', 1,0),
    linux_num = ifelse(linux=='yes',1,0),
    windows_num = ifelse(windows == 'yes',1,0),
    aws_num = ifelse(aws == 'yes', 1, 0)
  ) %>%
  filter(Gender %in% c("Female", "Male")) %>%
  filter(Year %in% 2018:2022) %>%
  filter(!is.na(AnnualSalary)) %>% 
  filter(Country == "United States") %>%
  filter(Employment == "Full-Time") %>%
  filter(AnnualSalary < 300000) %>%
  select(-c(Employment, US_State, Sexuality, Ethnicity, OrgSize, YearsCodePro, Age, PlatformWorkedWith, LanguageWorkedWith, DatabaseWorkedWith)) %>%
  mutate(
    Gender = as.factor(Gender),
    EdLevel = as.factor(EdLevel)) %>%
  mutate_at(
    vars(python:aws), 
    as.factor)
```


### Data engineering pipeline

Our [pipeline](https://github.com/tonythor/krijudato/blob/develop/functions.r) does the following: 

1. For each year, download raw survey data file from S3. 
2. Unify columns per year, and then union all years together.
3. Explode wide certain multi-value columns. For example, "PlatformWorkedWith" contains both AWS and Google Cloud.
4. Preprocess certain columns. For example, we aggregate a second grouped_ethnicity column that is only either minority, non-minority, or NA. 
3. Save the CSV file in the root directory so the markdown can load it from cache.

### How we filtered the base data set
We filtered our more than 500K raw records all the way down to 43,655 for this study. Our working dataset includes only those who: 

* Provided their salary

* Work in the United States

* Identify as male or female

* Have full time jobs

* Have an annual salary below 300,000

### A quick glimpse of filtered data

```{r message=FALSE, echo=FALSE}
glimpse(wide_stack)
```

### A high-level respondent overview
The range of respondents includes many types of careers, but is all highly technical in nature. As well, many more men than women responded to this survey, and that most likely implies several different kinds of bias. 

```{r message=FALSE, echo=FALSE}
salByJobType <- wide_stack %>%
  mutate(DevType = str_split_fixed(DevType, ';', 2)[, 1]) %>%
  filter(!is.na(AnnualSalary)) %>%
  group_by(DevType) %>%
  summarise(AvgSalary = mean(AnnualSalary, na.rm = TRUE)) %>%
  arrange(desc(AvgSalary)) %>%
  head(n = 20) %>%
  ggplot(aes(x = reorder(DevType, -AvgSalary), y = AvgSalary)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Top 20 Average Salaries in the U.S. by Job Type") +
  labs(x = "Job Type", y = "Average Salary")

respGender <- wide_stack %>%
  filter(Gender %in% c("Female", "Male")) %>%
  ggplot(aes(x = Year, fill = Gender)) +
  geom_bar(position = "dodge") +
  labs(title = "Respondents by gender over years",
    x = "Year",
    y = "Number of Respondents",
    fill = "Gender") +
  theme_minimal()
```

```{r fig.width=12}
grid.arrange(salByJobType, respGender, ncol = 2)
```

### A non-gender based look at correlation
We converted many independent variables to integers so we could see could look at correlation to the dependent variable.

```{r, warning = FALSE, message = FALSE, echo=FALSE}
numeric_data <- select(wide_stack, Year, AnnualSalary, 
  YearsCodeProAvg, OrgSizeAvg, AgeAvg, python_num,sql_num, java_num, javascript_num, ruby_num, php_num, c_num, swift_num, scala_num, r_num,rust_num, 
  julia_num, mysql_num, microsoftsqlserver_num, mongodb_num, postgresql_num, oracle_num, ibmdb2_num, redis_num, sqlite_num,mariadb_num, 
  microsoftazure_num, googlecloud_num, ibmcloudorwatson_num, kubernetes_num, linux_num, windows_num, aws_num)
cor_matrix <- cor(numeric_data, use = "complete.obs")
cor_with_salary <- cor_matrix["AnnualSalary",]
cor_with_salary <- cor_with_salary[-which(names(cor_with_salary) == "AnnualSalary")]
cor_df <- data.frame(Variable = names(cor_with_salary), Correlation = cor_with_salary)

corr_chart <- ggplot(cor_df, aes(x = Variable, y = Correlation)) +
  geom_bar(stat = "identity") +
  labs(title = "Correlations to Annual Salary", 
       x = "", 
       y = "Correlation coefficient") +
  theme_minimal() +
  ylim(-1, 1) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(face = "bold", hjust = 0.5))
```

```{r fig.width=12}
grid.arrange(corr_chart, ncol = 1)
```


### A quick look at gender discrepency
As a final series of charts, and as we alluded to in the project proposal, it wasn't just one or two variables showing a pay gap, it was all of them. We thought we'd add some more  descriptive box plots to this presentation before we started deeper analysis.  

```{r message=FALSE, echo=FALSE}
boxplot_base <- wide_stack %>% 
  filter(Gender %in% c("Female", "Male")) %>%
  filter(!is.na(AnnualSalary), !is.na(Gender))

# Filter the base data for each technology
aws_data_yes <- boxplot_base %>% filter(aws == "yes")
linux_data_yes <- boxplot_base %>% filter(linux == "yes")
oracle_data_yes <- boxplot_base %>% filter(oracle == "yes")

miniority <- boxplot_base %>% filter(ethnicity_grouped == "minority")
non_miniority <- boxplot_base %>% filter(ethnicity_grouped == "non-minority")
lgbqt <- boxplot_base %>% filter(sexuality_grouped == "lgbtq")
straight <- boxplot_base %>% filter(sexuality_grouped == "straight")


# Create the AWS plot
aws <- ggplot(aws_data_yes, aes(x = Gender, y = AnnualSalary, fill = Gender)) +
  geom_boxplot() +
  labs(title = "AWS People",
    x = "Gender",
    y = "Annual Salary",
    fill = "Gender") +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue")) +
  theme_minimal()

# Create the Linux plot
linux <- ggplot(linux_data_yes, aes(x = Gender, y = AnnualSalary, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Linux People",
    x = "Gender",
    y = "Annual Salary",
    fill = "Gender") +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue")) +
  theme_minimal()

# Create the Oracle plot
oracle <- ggplot(oracle_data_yes, aes(x = Gender, y = AnnualSalary, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Oracle People",
    x = "Gender",
    y = "Annual Salary",
    fill = "Gender") +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue")) +
  theme_minimal()

# Create the Minority plot
minority_plot <- ggplot(miniority, aes(x = Gender, y = AnnualSalary, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Minorities",
    x = "Gender",
    y = "Annual Salary",
    fill = "Gender") +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue")) +
  theme_minimal()

# Create the Non-Minority plot
non_minority_plot <- ggplot(non_miniority, aes(x = Gender, y = AnnualSalary, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Non-minorities",
    x = "Gender",
    y = "Annual Salary",
    fill = "Gender") +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue")) +
  theme_minimal()

# Create the LGBTQ plot
lgbqt_plot <- ggplot(lgbqt, aes(x = Gender, y = AnnualSalary, fill = Gender)) +
  geom_boxplot() +
  labs(title = "LGBTQ",
    x = "Gender",
    y = "Annual Salary",
    fill = "Gender") +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue")) +
  theme_minimal()

# Create the Straight plot
straight_plot <- ggplot(straight, aes(x = Gender, y = AnnualSalary, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Straight",
    x = "Gender",
    y = "Annual Salary",
    fill = "Gender") +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue")) +
  theme_minimal()
```

```{r fig.width=12}
grid.arrange(aws, linux, oracle, ncol = 3)
grid.arrange(minority_plot, non_minority_plot, lgbqt_plot , straight_plot, ncol = 4)
```



## Data analysis
Converting female and male salary distributions to z-scores to compare.
```{r, warning = FALSE, message = FALSE, echo = FALSE}
# calculate z-score
wide_stack <- wide_stack %>%
  group_by(Gender) %>%
  mutate(
    z_score = (AnnualSalary - mean(AnnualSalary)) / sd(AnnualSalary)
  ) %>%
  ungroup() 

wide_stack %>%
  ggplot(aes(x = z_score, y = as.factor(Gender), fill = Gender)) +
    geom_boxplot() +
    scale_y_discrete(labels = c("Female", "Male")) +
    labs(
      title = "Z-Score Distribution of Salaries by Gender",
      x = "Z-Score",
      y = "Gender"
    ) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      plot.title = element_text(face = "bold", hjust = 0.5),
      legend.position = "none"
    ) +
    coord_flip()
```

---

We will create a multiple linear regression model.

```{r}
wide_stack$Gender <- relevel(wide_stack$Gender, ref = "Male")
m_salary_gender <- lm(AnnualSalary ~ Gender, data = wide_stack)
summary(m_salary_gender)
```

From the above, we see that the p-value is 0.000000000000022%. Using a 95% confidence interval, having a p-value of less than 5% means that we can reject the null hypothesis. We can see that the adjusted $\R^2$ value is very small (0.6364%), which means that the model does not explain much of the variability of the dependent variable. The coefficient -14,112.9 means that, on average and after accounting for other factors in the model, being female is associated with a decrease of $14,112.9 in annual salary compared to males.

---

So, we will first add in all of the variables in our study to determine which are good predictors of the variance. We will also include the interaction between each variable and Gender, denoted by "Gender * Variable". 

```{r}
wide_stack$EdLevel<- relevel(wide_stack$EdLevel, ref = "Something Else")

m_salary <- lm(AnnualSalary ~ Gender + Gender:AgeAvg + Gender:ethnicity_grouped + Gender:sexuality_grouped + Gender:EdLevel + Gender:OrgSizeAvg 
+ Gender:YearsCodeProAvg + Gender:Year + Gender:python + Gender:r + Gender:scala + Gender:julia + Gender:microsoftazure + Gender:aws 
+ Gender:linux + Gender:windows + Gender:mysql + Gender:oracle + Gender:ibmdb2 + Gender:mongodb, data = wide_stack)

summary(m_salary)
```

---

From the previous summary, we can see that there are a few variables that have a very low p-value, which means that they are not statistically 
significant in the model. These variables are:

- EdLevel: Something Else
- mongodb
- julia

The $R^2$ value is 26.14%, which means that approximately 26.14% of the variability in the dependent variable (AnnualSalary) can be explained by the independent variables included in the model. The remaining 73.86% of the variability is unaccounted for by the model. The p-value is 0.000000000000022%,  which suggests that there is strong evidence that at least one of the predictors in the model has a non-zero effect, and the overall model is statistically significant. Hence, we can reject the null hypothesis (There is no significant difference in the mean annual salaries between male and females).

We will re-run the model with the above variables removed to see if this improves the $R^2$. 

---

```{r}
wide_stack_filtered <- wide_stack %>%
  filter(!EdLevel %in% c("Something Else"))

m_salary_filter <- lm(AnnualSalary ~ Gender + Gender:AgeAvg + Gender:ethnicity_grouped + Gender:sexuality_grouped + Gender:EdLevel + Gender:OrgSizeAvg + 
Gender:YearsCodeProAvg + Gender:Year + Gender:python + Gender:r + Gender:scala + Gender:microsoftazure + Gender:aws + Gender:linux + Gender:windows + 
Gender:mysql + Gender:oracle + Gender:ibmdb2, data = wide_stack_filtered)

summary(m_salary_filter)
```

---

From the previous summary, we can see that the $R^2$ value has improved to 26.16%. This is not much of an improvement, but after experimenting with removing other variables, it is the highest value attainable. This means that approximately 26.16% of the variability in the dependent variable (AnnualSalary) can be explained by the remaining independent variables included in the model. The p-value is still very small, which means that we can still reject the null hypothesis. 

## Assuring compliance with model conditions

The four required conditions of multiple linear regression are linearity, normality, constant variability and independence of residuals. After reviewing all four conditions below, we believe a multiple linear regression is valid to use. 

### Linearity
We can assume linearity as we can see ther is no obvious trend in the distrobution.

```{r, message = FALSE, warning = FALSE}
ggplot(data = m_salary, aes(x = .fitted, y = .resid)) +
  geom_point()
```

### Normality
We can assume normality as the line mostly falls on the normal line. 

```{r, warning = FALSE, message = FALSE}
ggplot(data = m_salary, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()
```

### Constant Variability
Points are scattered with no apparent pattern around 0, and therefore we can assume constant variability.

```{r}
ggplot(data = m_salary, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed")
```


### Independence

We assume independence. Each case represents an individual response, and responses even if done by the same people have a full year between them. 

## Conclusion

### Findings
After having whittled down gigabytes worth of data across 557 raw variables that we expanded into over 750 total variables, two things are clear to us. 

1. There is at least one more unkwon variable that plays a massive factor in describing the gap between gender pay in the technology jobs
2. That variable is not incldued in this study

### Reccomendations

We suspect further analyzing factors from this study will continue to be inconclusive, but our primary reccomendation is to keep this study going, to find funding, or do whatever it takes to persevere. We do believe there are three directions that would all be good to go down next. All thre eare implausable, but if we coudl dig into them, we are convident they would help us find influential pay gap variables. 

1. **Study salaries by gender and location**  Our study doens't take into account state and county. Perhaps this is a tiny town versus big city only problem. Or perhaps the pay gap is only in Portland Oregon. Our data does not provide that dimension. 

2. **Study company salaires by position and gender** Obviously, not all companies big or small have as significant of issues with pay, but certain companies are known to have a notoriusly masive pay gap. We could start with Oracle.  

3. **Study entire industires by position, gender and salary** There are software developers and project managers that do exactly the same thing in non profits, and in media. Perhaps the industry itself plays one of the biggest roles in the pay gap. 



